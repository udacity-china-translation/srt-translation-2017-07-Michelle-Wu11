1
00:00:00,400 --> 00:00:04,520
我们近期的网上案例来自 Facebook 和康奈尔大学的研究人员

2
00:00:04,520 --> 00:00:07,670
他们对情绪在社交媒体上的传播进行了研究

3
00:00:07,670 --> 00:00:11,640
在实验中 一组随机选择的参与者

4
00:00:11,640 --> 00:00:14,020
看到的是有较少负面贴子的新闻提要

5
00:00:14,020 --> 00:00:17,825
另外一组看到的是有较少正面贴子的新闻提要

6
00:00:17,825 --> 00:00:21,765
一周后 研究人员测量参与者的贴子

7
00:00:21,765 --> 00:00:23,365
看是更为正面还是更为负面

8
00:00:24,575 --> 00:00:28,625
Facebook 实验中参与者面临的风险

9
00:00:28,625 --> 00:00:31,925
比其他实验中参与者都要低很多

10
00:00:31,925 --> 00:00:34,575
对研究结果可能带来的好处也没有进行探讨

11
00:00:35,670 --> 00:00:40,040
这就是三个问题案例

12
00:00:40,040 --> 00:00:41,390
或者说存在潜在问题的实验

13
00:00:41,390 --> 00:00:45,670
显然这是并不常见的个案

14
00:00:45,670 --> 00:00:49,720
但正是这些个案促成了 IRB

15
00:00:49,720 --> 00:00:51,790
即机构审查委员会的成立

16
00:00:52,960 --> 00:00:55,345
IRB 对可能进行的实验进行审查

17
00:00:55,345 --> 00:00:58,380
以确保参与者得到充分的保护

18
00:00:58,380 --> 00:01:02,800
事实上 大部分的 IRB 与学术机构相关联

19
00:01:02,800 --> 00:01:06,918
互联网研究属于 IRB 审查的灰色地带

20
00:01:06,918 --> 00:01:10,928
即便如此 仍然要将保护参与者

21
00:01:10,928 --> 00:01:12,640
作为关注重点

22
00:01:12,640 --> 00:01:15,350
需要考虑的四个原则 一是风险

23
00:01:15,350 --> 00:01:19,080
即实验中参与者被暴露于哪种风险？

24
00:01:19,080 --> 00:01:20,470
二是好处

25
00:01:20,470 --> 00:01:23,500
即研究结果将产生何种好处？

26
00:01:23,500 --> 00:01:25,020
三是选择

27
00:01:25,020 --> 00:01:27,600
即参与者还有其他哪些选择？

28
00:01:27,600 --> 00:01:30,100
最后是隐私

29
00:01:30,100 --> 00:01:34,790
即参与者可以期待怎样的隐私保护？

30
00:01:34,790 --> 00:01:36,060
接下来我们将对这四个原则逐一探讨
